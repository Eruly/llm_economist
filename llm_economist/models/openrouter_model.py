"""
OpenRouter model implementation for the LLM Economist framework.
"""

from typing import Tuple, Optional
import os
import requests
import json
from time import sleep
from .base import BaseLLMModel


class OpenRouterModel(BaseLLMModel):
    """OpenRouter model implementation for accessing multiple models through OpenRouter API."""
    
    def __init__(self, model_name: str = "meta-llama/llama-3.1-8b-instruct", 
                 api_key: Optional[str] = None,
                 max_tokens: int = 1000, temperature: float = 0.7):
        """
        Initialize the OpenRouter model.
        
        Args:
            model_name: Name of the model to use on OpenRouter
            api_key: OpenRouter API key (if None, will look for OPENROUTER_API_KEY env var)
            max_tokens: Maximum number of tokens to generate
            temperature: Temperature for sampling
        """
        super().__init__(model_name, max_tokens, temperature)
        
        # Get API key from parameter or environment
        if api_key is None:
            api_key = os.getenv('OPENROUTER_API_KEY')
        
        if not api_key:
            raise ValueError("OpenRouter API key not found. Set OPENROUTER_API_KEY environment variable or pass api_key parameter.")
        
        self.api_key = api_key
        self.base_url = "https://openrouter.ai/api/v1"
        
        # Headers for OpenRouter API
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "HTTP-Referer": "https://github.com/sethkarten/LLMEconomist",
            "X-Title": "LLM Economist",
            "Content-Type": "application/json"
        }
        
    def send_msg(self, system_prompt: str, user_prompt: str, 
                 temperature: Optional[float] = None, 
                 json_format: bool = False) -> Tuple[str, bool]:
        """
        Send a message to the OpenRouter API and get a response.
        
        Args:
            system_prompt: System prompt to set the context
            user_prompt: User prompt/question
            temperature: Temperature override for this call
            json_format: Whether to request JSON format response
            
        Returns:
            Tuple of (response_text, is_json_valid)
        """
        if temperature is None:
            temperature = self.temperature
            
        retry_count = 0
        max_retries = 3
        
        while retry_count < max_retries:
            try:
                # Prepare the request payload
                payload = {
                    "model": self.model_name,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": self.max_tokens
                }
                
                # Add JSON format if requested (for compatible models)
                if json_format:
                    payload["response_format"] = {"type": "json_object"}
                
                # Make the API call
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=60
                )
                
                response.raise_for_status()
                result = response.json()
                
                if 'choices' not in result or len(result['choices']) == 0:
                    raise Exception(f"No response choices returned: {result}")
                
                message = result['choices'][0]['message']['content']

                if not self._validate_response(message):
                    self.logger.warning(f"Invalid response received: {message}")
                    retry_count += 1
                    continue

                if json_format:
                    parsed_response, is_json_valid = self._extract_json(message)
                    self._record_history(
                        system_prompt,
                        user_prompt,
                        message,
                        json_requested=True,
                        is_json_valid=is_json_valid,
                        parsed_response=parsed_response,
                    )
                    return parsed_response, is_json_valid

                self._record_history(
                    system_prompt,
                    user_prompt,
                    message,
                    json_requested=False,
                    is_json_valid=False,
                )
                return message, False
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429:  # Rate limit
                    self.logger.warning(f"Rate limit hit: {e}")
                    self._handle_rate_limit(retry_count, max_retries)
                    retry_count += 1
                else:
                    self.logger.error(f"HTTP error calling OpenRouter API: {e}")
                    raise
                    
            except requests.exceptions.RequestException as e:
                self.logger.error(f"Request error calling OpenRouter API: {e}")
                retry_count += 1
                if retry_count >= max_retries:
                    raise
                sleep(1)
                
            except Exception as e:
                self.logger.error(f"Error calling OpenRouter API: {e}")
                retry_count += 1
                if retry_count >= max_retries:
                    raise
                sleep(1)
        
        raise Exception(f"Failed to get response after {max_retries} retries")
    
    def get_models(self) -> list:
        """Get list of available models from OpenRouter."""
        try:
            response = requests.get(
                f"{self.base_url}/models",
                headers=self.headers,
                timeout=30
            )
            response.raise_for_status()
            return response.json()['data']
        except Exception as e:
            self.logger.error(f"Error getting models: {e}")
            return []
    
    @classmethod
    def get_popular_models(cls):
        """Get list of popular models available on OpenRouter."""
        return [
            "meta-llama/llama-3.1-8b-instruct",
            "meta-llama/llama-3.1-70b-instruct",
            "meta-llama/llama-3.1-405b-instruct",
            "anthropic/claude-3.5-sonnet",
            "anthropic/claude-3-haiku",
            "openai/gpt-4o",
            "openai/gpt-4o-mini",
            "openai/gpt-4-turbo",
            "google/gemini-pro-1.5",
            "google/gemini-flash-1.5",
            "mistralai/mistral-7b-instruct",
            "mistralai/mixtral-8x7b-instruct",
            "cohere/command-r-plus",
            "perplexity/llama-3.1-sonar-large-128k-online"
        ]
    
    def check_model_availability(self, model_name: str) -> bool:
        """Check if a specific model is available on OpenRouter."""
        try:
            models = self.get_models()
            return any(model['id'] == model_name for model in models)
        except:
            return False 
